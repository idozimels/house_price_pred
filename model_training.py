
# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IdZuH3vuF7WZ5l9evPmW6pYj6TmNN5st
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import ElasticNet
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import mean_squared_error
import joblib
from madlan_data_prep import prepare_data

excel_file = 'https://github.com/idozimels/house_price_pred/raw/main/output_all_students_Train_v10.xlsx'
data = pd.read_excel(excel_file, engine='openpyxl')

df = data.copy()
df = prepare_data(df)

x = df.drop("price", axis=1)
y = df.price.astype(float)

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

numerical_features = ['Area', 'hasElevator ', 'hasParking ', 'hasBars ', 'hasStorage ',
                      'hasBalcony ', 'hasMamad ', 'handicapFriendly ', 'floor']
categorical_features = ['City', 'type', 'condition ']

numerical_pipeline = Pipeline([
    ('imputation', SimpleImputer(strategy='most_frequent')),
    ('scaling', StandardScaler())])

categorical_pipeline = Pipeline([
    ('imputation', SimpleImputer(strategy='most_frequent')),
    ('one_hot_encoding', OneHotEncoder(handle_unknown='ignore'))])

preprocessing_pipeline = ColumnTransformer([
    ('numerical', numerical_pipeline, numerical_features),
    ('categorical', categorical_pipeline, categorical_features)])

model_pipeline = Pipeline([
    ('preprocessing', preprocessing_pipeline),
    ('feature_selection', SelectFromModel(ElasticNet(alpha=0.8, l1_ratio=1, random_state=42))),
    ('elastic_net', ElasticNet())])

param_grid = {
    'feature_selection__threshold': [0.1, 0.2, 0.3],
    'elastic_net__alpha': [0.1, 0.5, 1.0],
    'elastic_net__l1_ratio': [0.2, 0.5, 0.8]}

grid_search = GridSearchCV(model_pipeline, param_grid, cv=8, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

print("Best Hyperparameters:", grid_search.best_params_)
print("Best Cross-validation MSE:", -grid_search.best_score_)

final_model = grid_search.best_estimator_
final_model.fit(X_train, y_train)

y_pred = final_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("Test MSE:", mse)
rmse = np.sqrt(mse)
print("Test RMSE:", rmse)

joblib.dump(final_model, 'trained_model.pkl')